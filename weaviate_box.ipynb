{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2965d4b",
   "metadata": {},
   "source": [
    "## Python Jupyter Notebook Recipe: Weaviate + Box Integration with Cohere LLM\n",
    "\n",
    "Author: Alexander Novotny from Box\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Authenticate with Box using a developer token via the Box Python-gen SDK.\n",
    "2. Retrieve files from a specified Box folder, using Box's text representations.\n",
    "3. Generate embeddings for the file content using Cohere.\n",
    "4. Store the embeddings and metadata in Weaviate.\n",
    "5. Implement a q/a service to query the content using Weaviate’s vector search and Cohere’s language model.\n",
    "\n",
    "### Prerequisites\n",
    "- A Box account with a custom application and developer token (you can generate one in the Box Developer Console).\n",
    "- A Weaviate cloud instance.\n",
    "- A Cohere API key (sign up at https://cohere.ai/).\n",
    "- A Box folder ID containing supported files (e.g., `.txt`, `.pdf`, `.docx`).\n",
    "\n",
    "## Notes\n",
    "- **Box Folder ID**: Find this in the Box web interface URL (e.g., `https://app.box.com/folder/12345` → `12345`).\n",
    "- **File Types**: Only processes supported extensions (e.g., `.pdf`, `.docx`). Adjust `SUPPORTED_TEXT_FILE_TYPES` as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fe69d",
   "metadata": {},
   "source": [
    "### Step 1: Install Dependencies\n",
    "First, install the required Python packages in your Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "!pip3 install weaviate-client box-sdk-gen requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097ede8",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries\n",
    "Import the necessary libraries for Box, Weaviate, and Cohere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e318f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey\n",
    "from weaviate.classes.query import QueryReference\n",
    "from box_sdk_gen import BoxClient, BoxDeveloperTokenAuth\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a328b76",
   "metadata": {},
   "source": [
    "### Step 3: Authentication\n",
    "Set up authentication for Box, Weaviate, and Cohere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee79348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Box Developer Token (replace with your own)\n",
    "BOX_DEVELOPER_TOKEN = 'DEVELOPER_TOKEN'\n",
    "FOLDER_ID = 'BOX_FOLDER_ID'\n",
    "\n",
    "# Weaviate Instance URL and API Key (replace with your own)\n",
    "WEAVIATE_URL = 'WEAVIATE_URL'\n",
    "WEAVIATE_API_KEY = 'WEAVIATE_ADMIN_KEY'  # Optional, depending on setup\n",
    "\n",
    "# Cohere API Key (replace with your own)\n",
    "COHERE_API_KEY = 'COHERE_API_KEY'\n",
    "\n",
    "\n",
    "def main(box_token: str, weaviate_url: str, weaviate_api_key: str, cohere_api_key: str):\n",
    "    # Initialize Box Client\n",
    "    auth: BoxDeveloperTokenAuth = BoxDeveloperTokenAuth(token=box_token)\n",
    "    box_client: BoxClient = BoxClient(auth=auth)\n",
    "    \n",
    "    # Initialize Weaviate Client for WCS\n",
    "    weaviate_client = weaviate.connect_to_wcs(\n",
    "        cluster_url=weaviate_url,\n",
    "        auth_credentials=AuthApiKey(weaviate_api_key) if weaviate_api_key else None,\n",
    "        headers={\"X-Cohere-Api-Key\": cohere_api_key}\n",
    "    )\n",
    "    \n",
    "    # Return clients for use in subsequent steps\n",
    "    return box_client, weaviate_client\n",
    "\n",
    "# Call main to initialize clients\n",
    "box_client, weaviate_client = main(\n",
    "    BOX_DEVELOPER_TOKEN, WEAVIATE_URL, WEAVIATE_API_KEY, COHERE_API_KEY\n",
    ")\n",
    "print(\"Clients initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2eeeee",
   "metadata": {},
   "source": [
    "### Step 4: Define Weaviate Schema\n",
    "Create a schema in Weaviate to store document embeddings and metadata. We’ll use Cohere’s `text2vec-cohere` vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure\n",
    "\n",
    "# Check if the \"Document\" collection already exists\n",
    "if not weaviate_client.collections.exists(\"Documents\"):\n",
    "    # Create the collection explicitly\n",
    "    weaviate_client.collections.create(\n",
    "        name=\"Documents\",\n",
    "        generative_config=Configure.Generative.cohere(),\n",
    "        properties=[\n",
    "            Property(name=\"file_id\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "            Property(name=\"file_name\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "            Property(name=\"chunk_index\", data_type=DataType.INT, skip_vectorization=True),\n",
    "            Property(name=\"content\", data_type=DataType.TEXT),  # Vectorized by default\n",
    "            Property(name=\"created_date\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    " \n",
    "        ],\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_cohere()\n",
    "    )\n",
    "    print(\"Schema 'Documents' created successfully.\")\n",
    "else:\n",
    "    print(\"Schema 'Documents' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5c387",
   "metadata": {},
   "source": [
    "### Step 5: Retrieve Files from Box\n",
    "Define a function to fetch files from a specified Box folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported file types for text representation\n",
    "SUPPORTED_TEXT_FILE_TYPES = {\n",
    "    \".doc\", \".docx\", \".pdf\", \".txt\", \".html\", \".md\", \".json\", \".xml\",\n",
    "    \".ppt\", \".pptx\", \".key\",\n",
    "    \".xls\", \".xlsx\", \".csv\"\n",
    "}\n",
    "\n",
    "def is_supported_file_type(file_name):\n",
    "    \"\"\"Check if the file's extension is in the supported list.\"\"\"\n",
    "    return any(file_name.endswith(ext) for ext in SUPPORTED_TEXT_FILE_TYPES)\n",
    "\n",
    "def get_files_in_folder(client, folder_id):\n",
    "    \"\"\"Retrieve all supported files from a specified Box folder.\"\"\"\n",
    "    items = client.folders.get_folder_items(folder_id)\n",
    "    file_objects = []\n",
    "    for item in items.entries:\n",
    "        if item.type == 'file' and is_supported_file_type(item.name):\n",
    "            file_objects.append(client.files.get_file_by_id(item.id))\n",
    "    return file_objects\n",
    "\n",
    "files = get_files_in_folder(box_client, FOLDER_ID)\n",
    "print(f\"Found {len(files)} supported files in folder {FOLDER_ID}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d161508",
   "metadata": {},
   "source": [
    "### Step 6: Extract Text and Generate Chunks\n",
    "Extract text from files and prepare data for Weaviate. Note: This cleans up text and chunks the data with overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e358294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing cleanup function (unchanged)\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"Clean up the extracted text content.\"\"\"\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "    unwanted_patterns = [\n",
    "        \"\\\\n\", \"  —\", \"——————————\", \"—————————\", \"—————\",\n",
    "        r'\\\\u[\\dA-Fa-f]{4}', r'\\uf075', r'\\uf0b7'\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "    content = re.sub(r'(\\w)\\s*-\\s*(\\w)', r'\\1-\\2', content)\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    return content\n",
    "\n",
    "# Existing text extraction function (unchanged)\n",
    "def get_file_text_content(file, max_retries=5, delay=5):\n",
    "    \"\"\"Get text content from a file's representation with retry logic.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        special_client = box_client.with_extra_headers(extra_headers={\"x-rep-hints\": \"[extracted_text]\", \"x-box-ai-library\": \"weaviate\"})\n",
    "        file = special_client.files.get_file_by_id(file.id, fields=[\"representations\"])\n",
    "        if file.representations and file.representations.entries:\n",
    "            for rep in file.representations.entries:\n",
    "                if rep.representation == \"extracted_text\":\n",
    "                    download_url = rep.content.url_template.replace(\"{+asset_path}\", \"\") + '?access_token=' + box_client.auth.token\n",
    "                    response = requests.get(download_url)\n",
    "                    response.raise_for_status()\n",
    "                    return clean_up_text(response.text)\n",
    "                else:\n",
    "                    print(f\"Text representation not ready for file {file.id}\")\n",
    "                    raise ValueError(f\"Text representation not ready for file {file.id}\")\n",
    "        if attempt == max_retries - 1:\n",
    "            raise ValueError(f\"Text representation not ready for {file.name} after {max_retries} attempts.\")\n",
    "\n",
    "# New chunking function\n",
    "def chunk_text(text, chunk_size=4000, overlap=200):\n",
    "    \"\"\"Split text into chunks with specified size and overlap.\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# Modified extraction function with chunking\n",
    "def extract_text_and_generate_embeddings(files):\n",
    "    \"\"\"Extract text from supported files and yield chunked data.\"\"\"\n",
    "    for file in files:\n",
    "        try:\n",
    "            text = get_file_text_content(file)\n",
    "            chunks = chunk_text(text, chunk_size=4000, overlap=200)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                yield {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"file_name\": file.name,\n",
    "                    \"chunk_index\": i,\n",
    "                    \"content\": chunk,\n",
    "                    \"created_date\": file.created_at\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file.name}: {e}\")\n",
    "\n",
    "# Extract data from files\n",
    "data = list(extract_text_and_generate_embeddings(files))\n",
    "print(f\"Processed {len(data)} text files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f16a9",
   "metadata": {},
   "source": [
    "### Step 7: Import Data into Weaviate\n",
    "Batch import the data into Weaviate, where Cohere’s vectorizer will automatically generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84499d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import data into Weaviate\n",
    "def import_data_to_weaviate(data):\n",
    "    \"\"\"Import chunked data into Weaviate.\"\"\"\n",
    "    collection = weaviate_client.collections.get(\"Documents\")\n",
    "    with collection.batch.dynamic() as batch:\n",
    "        for item in data:\n",
    "            batch.add_object(properties=item)\n",
    "    print(f\"Imported {len(data)} chunks into Weaviate.\")\n",
    "\n",
    "# Import the data\n",
    "import_data_to_weaviate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093f125",
   "metadata": {},
   "source": [
    "### Step 8: Search and generate\n",
    "Ask a question and get a response based on the imported content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query here (update this variable as needed)\n",
    "query = \"INSERT A QUESTION HERE BASED ON THE CONTENT OF THE CONTENT IN THE FOLDER\"\n",
    "\n",
    "# Get the Documents collection\n",
    "documents = weaviate_client.collections.get(\"Documents\")\n",
    "\n",
    "# Perform a near-text search and generate a single grouped response\n",
    "gen_response = documents.generate.near_text(\n",
    "    query=query,\n",
    "    limit=5,  # Retrieve top 5 relevant chunks\n",
    "    grouped_task=f\"Using the following content chunks from Box documentation, provide a single answer to the question: '{query}'\\n\\n\"\n",
    "                 \"Answer:\",\n",
    "    grouped_properties=[\"content\"], \n",
    "    return_properties=[\"content\", \"file_name\", \"chunk_index\"]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "if gen_response.generated:\n",
    "    print(\"Generated Response:\")\n",
    "    print(gen_response.generated.strip())\n",
    "    print(\"\\nRelevant Chunks Used:\")\n",
    "    for obj in gen_response.objects:\n",
    "        print(f\"File: {obj.properties['file_name']} (Chunk {obj.properties['chunk_index']}): {obj.properties['content'][:100]}...\")\n",
    "else:\n",
    "    print(\"No response generated. Check query or data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
