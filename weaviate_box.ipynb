{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2965d4b",
   "metadata": {},
   "source": [
    "## Python Jupyter Notebook Recipe: Weaviate + Box Integration with Cohere LLM\n",
    "\n",
    "Author: Alexander Novotny from Box\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Authenticate with Box using a developer token via the Box Python-gen SDK.\n",
    "2. Create a Box folder and upload demo files.\n",
    "3. Retrieve the file content from the Box folder, using Box's text representations.\n",
    "4. Generate embeddings for the file content using Cohere.\n",
    "5. Store the embeddings and metadata in Weaviate.\n",
    "6. Implement a q/a service to query the content using Weaviate’s vector search and Cohere’s language model.\n",
    "\n",
    "### Prerequisites\n",
    "- A Box account with a custom application and developer token (you can generate one in the Box Developer Console).\n",
    "- A Weaviate cloud instance.\n",
    "- A Cohere API key (sign up at https://cohere.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fe69d",
   "metadata": {},
   "source": [
    "### Step 1: Install Dependencies\n",
    "First, install the required Python packages in your Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "!pip3 install weaviate-client box-sdk-gen requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097ede8",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries\n",
    "Import the necessary libraries for Box, Weaviate, and Cohere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey\n",
    "from box_sdk_gen import BoxClient, BoxDeveloperTokenAuth\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a328b76",
   "metadata": {},
   "source": [
    "### Step 3: Authentication\n",
    "Set up authentication for Box, Weaviate, and Cohere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee79348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Box Developer Token (replace with your own)\n",
    "BOX_DEVELOPER_TOKEN = 'DEVELOPER_TOKEN'\n",
    "\n",
    "# Weaviate Instance URL and API Key (replace with your own)\n",
    "WEAVIATE_URL = 'WEAVIATE_URL'\n",
    "WEAVIATE_API_KEY = 'WEAVIATE_ADMIN_KEY'  # Optional, depending on setup\n",
    "\n",
    "# Cohere API Key (replace with your own)\n",
    "COHERE_API_KEY = 'COHERE_API_KEY'\n",
    "\n",
    "\n",
    "def main(box_token: str, weaviate_url: str, weaviate_api_key: str, cohere_api_key: str):\n",
    "    # Initialize Box Client\n",
    "    auth: BoxDeveloperTokenAuth = BoxDeveloperTokenAuth(token=box_token)\n",
    "    box_client: BoxClient = BoxClient(auth=auth)\n",
    "    \n",
    "    # Initialize Weaviate Client for WCS\n",
    "    weaviate_client = weaviate.connect_to_wcs(\n",
    "        cluster_url=weaviate_url,\n",
    "        auth_credentials=AuthApiKey(weaviate_api_key) if weaviate_api_key else None,\n",
    "        headers={\"X-Cohere-Api-Key\": cohere_api_key}\n",
    "    )\n",
    "    \n",
    "    # Return clients for use in subsequent steps\n",
    "    return box_client, weaviate_client\n",
    "\n",
    "# Call main to initialize clients\n",
    "box_client, weaviate_client = main(\n",
    "    BOX_DEVELOPER_TOKEN, WEAVIATE_URL, WEAVIATE_API_KEY, COHERE_API_KEY\n",
    ")\n",
    "print(\"Clients initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2eeeee",
   "metadata": {},
   "source": [
    "### Step 4: Define Weaviate Schema\n",
    "Create a schema in Weaviate to store document embeddings and metadata. We’ll use Cohere’s `text2vec-cohere` vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure\n",
    "\n",
    "# Check if the \"Document\" collection already exists\n",
    "if not weaviate_client.collections.exists(\"Documents\"):\n",
    "    # Create the collection explicitly\n",
    "    weaviate_client.collections.create(\n",
    "        name=\"Documents\",\n",
    "        generative_config=Configure.Generative.cohere(),\n",
    "        properties=[\n",
    "            Property(name=\"file_id\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "            Property(name=\"file_name\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "            Property(name=\"chunk_index\", data_type=DataType.INT, skip_vectorization=True),\n",
    "            Property(name=\"content\", data_type=DataType.TEXT),  # Vectorized by default\n",
    "            Property(name=\"created_date\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    " \n",
    "        ],\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_cohere()\n",
    "    )\n",
    "    print(\"Schema 'Documents' created successfully.\")\n",
    "else:\n",
    "    print(\"Schema 'Documents' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12b695",
   "metadata": {},
   "source": [
    "### Step 5: Upload files to Box\n",
    "Uploads demo content to Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27076bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported file types for text representation\n",
    "SUPPORTED_TEXT_FILE_TYPES = {\n",
    "    \".doc\", \".docx\", \".pdf\", \".txt\", \".html\", \".md\", \".json\", \".xml\",\n",
    "    \".ppt\", \".pptx\", \".key\",\n",
    "    \".xls\", \".xlsx\", \".csv\"\n",
    "}\n",
    "\n",
    "def is_supported_file_type(file_name):\n",
    "    \"\"\"Check if the file's extension is in the supported list.\"\"\"\n",
    "    return any(file_name.endswith(ext) for ext in SUPPORTED_TEXT_FILE_TYPES)\n",
    "\n",
    "def create_and_populate_folder(client):\n",
    "    \"\"\"Create a folder in Box and upload supported files from the local demo_files directory.\"\"\"\n",
    "    # Create a new folder in the root directory (parent_id='0')\n",
    "    folder = client.folders.create_folder(name=\"Box_Weaviate_Demo_Folder\", parent_id=\"0\")\n",
    "    print(f\"Created folder 'Demo_Folder' with ID: {folder.id}\")\n",
    "\n",
    "    # Define the local demo_files directory\n",
    "    demo_dir = Path(\"demo_files\")\n",
    "    if not demo_dir.exists():\n",
    "        raise FileNotFoundError(\"Please create a 'demo_files' directory with example files.\")\n",
    "\n",
    "    # Get all supported files in the demo_files directory and upload them\n",
    "    file_objects = []\n",
    "    for file_path in demo_dir.iterdir():\n",
    "        if file_path.is_file() and is_supported_file_type(file_path.name):\n",
    "            with open(file_path, \"rb\") as file_content:\n",
    "                uploaded_file = client.files.upload_file(\n",
    "                    file_content=file_content,\n",
    "                    file_name=file_path.name,\n",
    "                    parent_id=folder.id\n",
    "                )\n",
    "                file_objects.append(uploaded_file)  # Store the uploaded file object\n",
    "                print(f\"Uploaded {file_path.name} with ID: {uploaded_file.id}\")\n",
    "        elif file_path.is_file():\n",
    "            print(f\"Skipped {file_path.name} - unsupported file type.\")\n",
    "\n",
    "    if not file_objects:\n",
    "        print(\"Warning: No supported files were uploaded from demo_files directory.\")\n",
    "    \n",
    "    return file_objects  # Return the list of uploaded file objects\n",
    "\n",
    "# Create folder and get the uploaded file objects\n",
    "files = create_and_populate_folder(box_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d161508",
   "metadata": {},
   "source": [
    "### Step 6: Extract Text and Generate Chunks\n",
    "Extract text from files and prepare data for Weaviate. Note: This cleans up text and chunks the data with overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e358294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing cleanup function (unchanged)\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"Clean up the extracted text content.\"\"\"\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "    unwanted_patterns = [\n",
    "        \"\\\\n\", \"  —\", \"——————————\", \"—————————\", \"—————\",\n",
    "        r'\\\\u[\\dA-Fa-f]{4}', r'\\uf075', r'\\uf0b7'\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "    content = re.sub(r'(\\w)\\s*-\\s*(\\w)', r'\\1-\\2', content)\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    return content\n",
    "\n",
    "# Existing text extraction function (unchanged)\n",
    "def get_file_text_content(file, max_retries=5, delay=5):\n",
    "    \"\"\"Get text content from a file's representation with retry logic.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        special_client = box_client.with_extra_headers(extra_headers={\"x-rep-hints\": \"[extracted_text]\", \"x-box-ai-library\": \"weaviate\"})\n",
    "        file = special_client.files.get_file_by_id(file.id, fields=[\"representations\"])\n",
    "        if file.representations and file.representations.entries:\n",
    "            for rep in file.representations.entries:\n",
    "                if rep.representation == \"extracted_text\":\n",
    "                    download_url = rep.content.url_template.replace(\"{+asset_path}\", \"\") + '?access_token=' + box_client.auth.token\n",
    "                    response = requests.get(download_url)\n",
    "                    response.raise_for_status()\n",
    "                    return clean_up_text(response.text)\n",
    "                else:\n",
    "                    print(f\"Text representation not ready for file {file.id}\")\n",
    "                    raise ValueError(f\"Text representation not ready for file {file.id}\")\n",
    "        if attempt == max_retries - 1:\n",
    "            raise ValueError(f\"Text representation not ready for {file.name} after {max_retries} attempts.\")\n",
    "\n",
    "# New chunking function\n",
    "def chunk_text(text, chunk_size=4000, overlap=200):\n",
    "    \"\"\"Split text into chunks with specified size and overlap.\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# Modified extraction function with chunking\n",
    "def extract_text_and_generate_embeddings(files):\n",
    "    \"\"\"Extract text from supported files and yield chunked data.\"\"\"\n",
    "    for file in files:\n",
    "        try:\n",
    "            text = get_file_text_content(file)\n",
    "            chunks = chunk_text(text, chunk_size=4000, overlap=200)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                yield {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"file_name\": file.name,\n",
    "                    \"chunk_index\": i,\n",
    "                    \"content\": chunk,\n",
    "                    \"created_date\": file.created_at\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file.name}: {e}\")\n",
    "\n",
    "# Extract data from files\n",
    "data = list(extract_text_and_generate_embeddings(files))\n",
    "print(f\"Processed {len(data)} text files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f16a9",
   "metadata": {},
   "source": [
    "### Step 7: Import Data into Weaviate\n",
    "Batch import the data into Weaviate, where Cohere’s vectorizer will automatically generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84499d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import data into Weaviate\n",
    "def import_data_to_weaviate(data):\n",
    "    \"\"\"Import chunked data into Weaviate.\"\"\"\n",
    "    collection = weaviate_client.collections.get(\"Documents\")\n",
    "    with collection.batch.dynamic() as batch:\n",
    "        for item in data:\n",
    "            batch.add_object(properties=item)\n",
    "    print(f\"Imported {len(data)} chunks into Weaviate.\")\n",
    "\n",
    "# Import the data\n",
    "import_data_to_weaviate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093f125",
   "metadata": {},
   "source": [
    "### Step 8: Search\n",
    "Ask a question and get a response based on the imported content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query here (update this variable as needed)\n",
    "query = \"Based on Google and Apple's reports, which company has the most revenue?\"\n",
    "\n",
    "# Get the Documents collection\n",
    "documents = weaviate_client.collections.get(\"Documents\")\n",
    "\n",
    "# Perform a near-text search and generate a single grouped response\n",
    "gen_response = documents.generate.near_text(\n",
    "    query=query,\n",
    "    limit=5,  # Retrieve top 5 relevant chunks\n",
    "    grouped_task=f\"Using the following content chunks from Box documentation, provide a single answer to the question: '{query}'\\n\\n\"\n",
    "                 \"Answer:\",\n",
    "    grouped_properties=[\"content\"], \n",
    "    return_properties=[\"content\", \"file_name\", \"chunk_index\"]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "if gen_response.generated:\n",
    "    print(\"Generated Response:\")\n",
    "    print(gen_response.generated.strip())\n",
    "    print(\"\\nRelevant Chunks Used:\")\n",
    "    for obj in gen_response.objects:\n",
    "        print(f\"File: {obj.properties['file_name']} (Chunk {obj.properties['chunk_index']}): {obj.properties['content'][:100]}...\")\n",
    "else:\n",
    "    print(\"No response generated. Check query or data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
